{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def salvar_html(html, filename):\n",
    "    \"\"\"Salva o resultado de uma requisição para visualização (sem css) no browser\n",
    "    \"\"\"\n",
    "    with open(filename,'w') as myf:\n",
    "        myf.write(html)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup do browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mechanize\n",
    "from urllib import urlencode\n",
    "from bs4 import BeautifulSoup as bsoup\n",
    "import sqlite3\n",
    "#Browser\n",
    "driver = mechanize.Browser()\n",
    "driver.set_handle_robots(False)\n",
    "driver.addheaders = [('User-agent',\n",
    "                    'Mozilla/5.0 (compatible; ABrowse 0.4; Syllable)')]\n",
    "\n",
    "clear_cookies = driver._ua_handlers['_cookies'].cookiejar.clear\n",
    "#URLs\n",
    "base_url = \"https://www.ncbi.nlm.nih.gov\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encontrando os artigos na primeira página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "risk AND machine learning - PMC - NCBI\n",
      "1\n",
      "\n",
      "Progressive sampling-based Bayesian optimization for efficient and automatic machine learning model selection\n",
      "\n",
      "MLBCD: a machine learning tool for big clinical data\n",
      "\n",
      "Can machine-learning improve cardiovascular risk prediction using routine clinical data?\n",
      "\n",
      "Machine Learning and Radiology\n",
      "\n",
      "Accuracy of automated classification of major depressive disorder as a function of symptom severity\n"
     ]
    }
   ],
   "source": [
    "### Pesquisar\n",
    "pesquisa = {'term':'risk AND machine learning'}\n",
    "clear_cookies()\n",
    "resposta = driver.open(base_url + '/pmc/', urlencode(pesquisa))\n",
    "\n",
    "### Pegar resultados\n",
    "soup = bsoup(resposta.read(), \"html5lib\")\n",
    "#Título da página\n",
    "print soup.findAll('title')[0].text\n",
    "# Número da página\n",
    "print soup.findAll('input',id='pageno')[0]['value'] + '\\n'\n",
    "#Títulos dos papers encontrados\n",
    "links = soup.findAll(\"div\", {\"class\":\"title\"})\n",
    "print '\\n\\n'.join([link.text for link in links[:5]])\n",
    "articles = links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encontrando os artigos depois da primeira página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "risk AND machine learning - PMC - NCBI\n",
      "3\n",
      "\n",
      "Machine Learning Algorithms Outperform Conventional Regression Mo...\n",
      "\n",
      "Using Machine Learning and Natural Language Processing Algorithms...\n",
      "\n",
      "A Cognitive Machine Learning Algorithm for Cardiac Imaging: A Pil...\n"
     ]
    }
   ],
   "source": [
    "from imports_pmc import _querystring, _pageno\n",
    "### Pesquisar, setando o request com o número da página\n",
    "_querystring[_pageno] = 3\n",
    "resposta = driver.open(\"https://www.ncbi.nlm.nih.gov/pmc/\",\n",
    "                       urlencode(_querystring)\n",
    "                      )\n",
    "\n",
    "### Pegar resultados\n",
    "soup = bsoup(resposta.read(), \"html5lib\")\n",
    "#Título da página\n",
    "print soup.findAll('title')[0].text\n",
    "# Número da página\n",
    "print soup.findAll('input',id='pageno')[0]['value'] + '\\n'\n",
    "#Títulos dos papers encontrados\n",
    "links = soup.findAll(\"div\", {\"class\":\"title\"})\n",
    "print '\\n\\n'.join([link.text[:65] + '...' for link in links[:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/pmc/articles/PMC3335189/',\n",
       " u'/pmc/articles/PMC4516296/',\n",
       " u'/pmc/articles/PMC4336000/']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[link.findAll('a', href=True)[0]['href'] for link in links[:3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Pegando as keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e mais algum parágrafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressive sampling-based Bayesian optimization for efficient an...\n",
      "\n",
      "Automatic machine learning model selection, Bayesian optimization, Progressive sampling, Clinical big data...\n",
      "\n",
      "Machine learning is broadly used for clinical data analysis. Before training a model, a machine learning algorithm must be selected. Also, the values of one or more model parameters termed hyper-parameters must be set. Selecting algorithms and hyper-parameter values requires advanced machine learning knowledge and many labor-intensive manual iterations. To lower the bar to machine learning, miscellaneous automatic selection methods for algorithms and/or hyper-parameter values have been proposed. Existing automatic selection methods are inefficient on large data sets. This poses a challenge for using machine learning in the clinical big data era....\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for article in articles[:1]:\n",
    "    url = base_url + article.findAll('a', href=True)[0]['href']\n",
    "    resposta = driver.open(url)\n",
    "    soup = bsoup(resposta.read(), \"html5lib\")\n",
    "    #Título da página\n",
    "    print soup.findAll('title')[0].text[:65] + '...\\n'\n",
    "    try:\n",
    "        print soup.findAll('span',{\"class\":\"kwd-text\"})[0].text+ '...\\n'\n",
    "    except:\n",
    "        pass\n",
    "    print soup.findAll('p',{\"class\":\"p p-first-last\"})[0].text+ '...\\n'\n",
    "    \n",
    "    print '\\n\\n'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Cruzando as palavras-chave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ou seja, fazendo a busca de par em par de palavras-chave e salvando os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*]resgatando titulos de Coronary Artery Disease AND Image processing ok\n",
      "[-]lendo  Cardiac magnetic resonance and computed tomography angiography fo(...) ok\n",
      "[-]lendo  Noninvasive FFR derived from coronary CT angiography in the manag(...) ok\n",
      "[-]lendo  Assessment of stable coronary artery disease by cardiovascular ma(...) ok\n",
      "[-]lendo  Total Coronary Atherosclerotic Plaque Burden Assessment by CT Ang(...) ok\n",
      "[-]lendo  Visualization of Coronary Wall Atherosclerosis in Asymptomatic Su(...) ok\n",
      "[-]lendo  Prevalence of Coronary Artery Disease Evaluated by Coronary CT An(...) ok\n",
      "[-]lendo  The coronary circulation in exercise training(...) ok\n",
      "[-]lendo  CT angiography in the diagnosis of cardiovascular disease: a tran(...) ok\n",
      "[-]lendo  Coronary CT Angiography in Heavily Calcified Coronary Arteries: I(...) ok\n",
      "[-]lendo  Coronary CT Angiography in the Quantitative Assessment of Coronar(...) ok\n",
      "[*] fim: resultados salvos em stems2017-11-29-22:14:23.934958.txt\n"
     ]
    }
   ],
   "source": [
    "from imports_pmc import _querystring, _pageno\n",
    "from datetime import datetime\n",
    "\n",
    "domain_specific = [\n",
    "    'Coronary Artery Disease',\n",
    "    'Arterial Coronary Syndrome',\n",
    "    'Patient Assessment',\n",
    "    'Risk Stratification',\n",
    "    'Risk Score',\n",
    "    'Angiography',\n",
    "    'Tomography'\n",
    "]\n",
    "keywords = [\n",
    "    'Image processing',\n",
    "    'image segmentation',\n",
    "    'Artificial Intelligence',\n",
    "    'Deep Learning'\n",
    "]\n",
    "articles_per_page = 5\n",
    "page_depth = 2\n",
    "\n",
    "stems = {}\n",
    "\n",
    "driver = mechanize.Browser()\n",
    "driver.set_handle_robots(False)\n",
    "driver.addheaders = [('User-agent',\n",
    "                    'Mozilla/5.0 (compatible; ABrowse 0.4; Syllable)')]\n",
    "\n",
    "clear_cookies = driver._ua_handlers['_cookies'].cookiejar.clear\n",
    "\n",
    "for domain in domain_specific[:1]:\n",
    "    for keyword in keywords[:1]:\n",
    "        term = ' AND '.join((domain, keyword))\n",
    "        research = {'term': term}\n",
    "        stem = []\n",
    "        append = stem.append\n",
    "        ###\n",
    "        ### Primeira página\n",
    "        ###\n",
    "        clear_cookies()\n",
    "        print '[*]resgatando titulos de',term,\n",
    "        resposta = driver.open(base_url + '/pmc/', urlencode(research))\n",
    "        print 'ok'\n",
    "        # Pegar resultados\n",
    "        soup = bsoup(resposta.read(), \"html5lib\")\n",
    "        # Articles encontrados\n",
    "        articles = soup.findAll(\"div\", {\"class\":\"title\"})\n",
    "        \n",
    "        for article in articles[:articles_per_page]:\n",
    "            # Reunir conteúdo de cada paper\n",
    "            content = {}\n",
    "            url = base_url + article.findAll('a', href=True)[0]['href']\n",
    "            print '[-]lendo ',article.text[:65].replace('\\n',' ') +'(...)',\n",
    "            resposta = driver.open(url)\n",
    "            print 'ok'\n",
    "            soup = bsoup(resposta.read(), \"html5lib\")\n",
    "            content['title'] = soup.findAll('title')[0].text\n",
    "            content['url'] = url\n",
    "            \n",
    "            try:\n",
    "                content['kwd'] = soup.findAll('span',{\"class\":\"kwd-text\"})[0].text\n",
    "            except:\n",
    "                content['kwd'] = '-'\n",
    "            try:\n",
    "                content['p'] = soup.findAll('p',{\"class\":\"p p-first-last\"})[0].text\n",
    "                content['p'] += soup.findAll('p',{\"class\":\"p p-first-last\"})[1].text\n",
    "            except:\n",
    "                content['p'] = '-'\n",
    "            \n",
    "            append(content)\n",
    "            \n",
    "        ###\n",
    "        ### Segunda página\n",
    "        ###\n",
    "        for page in range(2,page_depth + 1):\n",
    "            _querystring[_pageno] = page\n",
    "            resposta = driver.open(base_url + '/pmc/', urlencode(_querystring))\n",
    "            \n",
    "            # Pegar resultados\n",
    "            soup = bsoup(resposta.read(), \"html5lib\")\n",
    "            # Articles encontrados\n",
    "            articles = soup.findAll(\"div\", {\"class\":\"title\"})\n",
    "            \n",
    "            for article in articles[:articles_per_page]:\n",
    "                # Reunir conteúdo de cada paper\n",
    "                content = {}\n",
    "                url = base_url + article.findAll('a', href=True)[0]['href']\n",
    "                print '[-]lendo ',article.text[:65].replace('\\n',' ') +'(...)',\n",
    "                resposta = driver.open(url)\n",
    "                print 'ok'\n",
    "                soup = bsoup(resposta.read(), \"html5lib\")\n",
    "                content['title'] = soup.findAll('title')[0].text\n",
    "                content['url'] = url\n",
    "                \n",
    "                try:\n",
    "                    content['kwd'] = soup.findAll('span',{\"class\":\"kwd-text\"})[0].text\n",
    "                except:\n",
    "                    content['kwd'] = '-'\n",
    "                try:\n",
    "                    content['p'] = soup.findAll('p',{\"class\":\"p p-first-last\"})[0].text\n",
    "                    content['p'] += soup.findAll('p',{\"class\":\"p p-first-last\"})[1].text\n",
    "                except:\n",
    "                    content['p'] = '-'\n",
    "\n",
    "                append(content)\n",
    "                \n",
    "        stems[term] = stem\n",
    "    filename = \"stems\" + str(datetime.now()).replace(' ','-') + '.txt'\n",
    "    with open(filename, 'w') as myf:\n",
    "        myf.write(str(stems))\n",
    "    print '[*] fim: resultados salvos em',filename\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Selecionando artigos interativamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Extraindo artigos de stems2017-11-29-22:14:23.934958.txt\n",
      "Cardiac magnetic resonance and computed tomography angiography for clinical imaging of stable coronary artery disease. Diagnostic classification and risk stratification \n",
      "\n",
      "coronary artery disease, atherosclerotic plaque, coronary computed tomography, cardiac magnetic resonance, risk stratification \n",
      "\n",
      "Despite advances in the pharmacologic and interventional treatment of coronary artery disease (CAD), atherosclerosis remains the leading cause of death in Western societies. X-ray coronary angiography has been the modality of choice for diagnosing the presence and extent of CAD. However, this technique is invasive and provides limited information on the composition of atherosclerotic plaque. Coronary computed tomography angiography (CCTA) and cardiac magnetic resonance (CMR) have emerged as promising non-invasive techniques for the clinical imaging of CAD. Hereby, CCTA allows for visualization of coronary calcification, lumen narrowing and atherosclerotic plaque composition. In this regard, data from the CONFIRM Registry recently demonstrated that both atherosclerotic plaque burden and lumen narrowing exhibit incremental value for the prediction of future cardiac events. However, due to technical limitations with CCTA, resulting in false positive or negative results in the presence of severe calcification or motion artifacts, this technique cannot entirely replace invasive angiography at the present time. CMR on the other hand, provides accurate assessment of the myocardial function due to its high spatial and temporal resolution and intrinsic blood-to-tissue contrast. Hereby, regional wall motion and perfusion abnormalities, during dobutamine or vasodilator stress, precede the development of ST-segment depression and anginal symptoms enabling the detection of functionally significant CAD. While CT generally offers better spatial resolution, the versatility of CMR can provide information on myocardial function, perfusion, and viability, all without ionizing radiation for the patients. Technical developments with these 2 non-invasive imaging tools and their current implementation in the clinical imaging of CAD will be presented and discussed herein.The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest. \n",
      "\n",
      "Ação apaga\n",
      "apagando\n",
      "Noninvasive FFR derived from coronary CT angiography in the management of coronary artery disease: technology and clinical update \n",
      "\n",
      "fractional flow reserve, coronary computed tomographic angiography, FFRCT, cFFR \n",
      "\n",
      "After a decade of clinical use of coronary computed tomographic angiography (CCTA) to evaluate the anatomic severity of coronary artery disease, new methods of deriving functional information from CCTA have been developed. These methods utilize the anatomic information provided by CCTA in conjunction with computational fluid dynamics to calculate fractional flow reserve (FFR) values from CCTA image data sets. Computed tomography-derived FFR (CT-FFR) enables the identification of lesion-specific drop noninvasively. A three-dimensional CT-FFR modeling technique, which provides FFR values throughout the coronary tree (HeartFlow FFRCT analysis), has been validated against measured FFR and is now approved by the US Food and Drug Administration for clinical use. This technique requires off-site supercomputer analysis. More recently, a one-dimensional computational analysis technique (Siemens cFFR), which can be performed on on-site workstations, has been developed and is currently under investigation. This article reviews CT-FFR technology and clinical evidence for its use in stable patients with suspected coronary artery disease.Intermediate degrees of stenosis (30%–70%) present the greatest challenge in the diagnosis of CAD. Since hemodynamically significant lesions are occasionally observed in intermediate lesions with <70% stenosis,13 the use of invasive FFR is recommended to evaluate the function of intermediate coronary lesions as a class IIa indication.6 However, given the relatively lower prevalence of lesion-specific pressure drop caused by intermediate stenosis compared to that of severe stenosis in the FAME study,13 CT-derived FFR would be of great use for assessing the functional significance of intermediate lesions to avoid unnecessary ICA and help in treatment decision making. Table 2 provides a summary of the studies of FFRCT and cFFR. Similar to the overall diagnostic accuracy of CT-derived FFR, all studies demonstrated high diagnostic performance for intermediate stenosis, with the highest accuracy and specificity for FFRCT.24,31,38,39 \n",
      "\n",
      "Ação apaga\n",
      "apagando\n",
      "Assessment of stable coronary artery disease by cardiovascular magnetic resonance imaging: Current and emerging techniques \n",
      "\n",
      "Cardiovascular magnetic resonance, Coronary heart disease, Myocardial perfusion, Viability, Prognosis \n",
      "\n",
      "Coronary artery disease (CAD) is a leading cause of death and disability worldwide. Cardiovascular magnetic resonance (CMR) is established in clinical practice guidelines with a growing evidence base supporting its use to aid the diagnosis and management of patients with suspected or established CAD. CMR is a multi-parametric imaging modality that yields high spatial resolution images that can be acquired in any plane for the assessment of global and regional cardiac function, myocardial perfusion and viability, tissue characterisation and coronary artery anatomy, all within a single study protocol and without exposure to ionising radiation. Advances in technology and acquisition techniques continue to progress the utility of CMR across a wide spectrum of cardiovascular disease, and the publication of large scale clinical trials continues to strengthen the role of CMR in daily cardiology practice. This article aims to review current practice and explore the future directions of multi-parametric CMR imaging in the investigation of stable CAD.Although 1.5T is remains the standard field strength used in clinical CMR, imaging at a higher field strength of 3.0T offers increased signal to noise and contrast to noise ratios thereby giving improved spatial and temporal enhancement[27]. Consequently the diagnostic accuracy of perfusion imaging at 3.0T may be improved, and in a small direct comparison of CMR perfusion at 1.5T, 3.0T (n = 61) showed greater diagnostic accuracy in both single vessel (AUC: 0.89 vs 0.70; P < 0.05) and multi-vessel disease (AUC: 0.95 vs 0.82, P < 0.05)[28]. Furthermore, 3.0T has been compared to 1.5T using FFR as reference standard, corroborating it’s superior diagnostic accuracy[29,30]. The higher 3.0T field strength does however pose challenges with greater field inhomogeneity, susceptibility artefacts and higher local energy deposition. Also, many implants deemed “MR compatible” at 1.5T cannot be scanned at 3.0T[31]. These issues are however being overcome with improved technology and the use of multi-transmit radiofrequency CMR techniques improving field homogeneity[32]. \n",
      "\n",
      "Ação apaga\n",
      "apagando\n",
      "Total Coronary Atherosclerotic Plaque Burden Assessment by CT Angiography for Detecting Obstructive Coronary Artery Disease Associated with Myocardial Perfusion Abnormalities \n",
      "\n",
      "- \n",
      "\n",
      "Total atherosclerotic plaque burden assessment by CT angiography (CTA) is a promising tool for diagnosis and prognosis of coronary artery disease (CAD) but its validation is restricted to small clinical studies. We tested the feasibility of semi-automatically derived coronary atheroma burden assessment for identifying patients with hemodynamically significant CAD in a large cohort of patients with heterogenous characteristics.This study focused on the CTA component of the CORE320 study population. A semi-automated contour detection algorithm quantified total coronary atheroma volume defined as the difference between vessel and lumen volume. Percent atheroma volume (PAV = [total atheroma volume/total vessel volume]×100) was the primary metric for assessment (n=374). The area under the receiver operating characteristic curve (AUC) determined the diagnostic accuracy for identifying patients with hemodynamically significant CAD defined as ≥50% stenosis by quantitative coronary angiography and associated myocardial perfusion abnormality by SPECT. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import webbrowser\n",
    "from ast import literal_eval\n",
    "import re\n",
    "\n",
    "with open(filename,'r') as myf:\n",
    "    print '[*] Extraindo artigos de', filename\n",
    "    s = myf.read()\n",
    "    stems = literal_eval(s)\n",
    "for key in stems.keys():\n",
    "    i = 0\n",
    "    while i < len(stems[key]):\n",
    "        article = stems[key][i]\n",
    "        print article['title'],'\\n'\n",
    "        print article['kwd'],'\\n'\n",
    "        print article['p'],'\\n'\n",
    "        \n",
    "        apagar = re.compile(\"(apa|del|rem)\",re.IGNORECASE)\n",
    "        url = re.compile(\"(url|link|ender|site|abr)\",re.IGNORECASE)\n",
    "        proximo = re.compile(\"(con|ava|pro|nex)\",re.IGNORECASE)\n",
    "        sair = re.compile(\"(sai|lea|exi|fin)\",re.IGNORECASE)\n",
    "        \n",
    "        match = False\n",
    "        while not match:\n",
    "            act = raw_input(\"Ação \")\n",
    "            if apagar.match(act):\n",
    "                print 'apagando'\n",
    "                stems[key].remove(article)\n",
    "                match = True\n",
    "                i -= 1\n",
    "            elif url.match(act):\n",
    "                print 'abrindo'\n",
    "                i -= 1\n",
    "                webbrowser.open(article['url'])\n",
    "                match = True\n",
    "            elif proximo.match(act) or act == '':\n",
    "                print 'continuando'\n",
    "                match = True\n",
    "                continue\n",
    "            elif sair.match(act):\n",
    "                i = len(stems[key])\n",
    "                match = True\n",
    "            else:\n",
    "                print 'invalido!'\n",
    "        i += 1\n",
    "    filename = \"stems\" + str(datetime.now()).replace(' ','-') + '.txt'\n",
    "    with open(filename, 'w') as myf:\n",
    "        myf.write(str(stems))\n",
    "        print '[*] resultados salvos em',filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stems2017-11-29-21:55:15.401655.txt'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
