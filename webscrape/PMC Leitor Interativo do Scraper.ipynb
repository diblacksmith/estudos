{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "stems = {'term':[{'p':'paragraph','url':'https://www.ncbi.nlm.nih.gov/pmc/','title':'1','kwd':'keywords'},\n",
    "                {'p':'paragraph','url':'https://www.ncbi.nlm.nih.gov/pmc/','title':'2','kwd':'keywords'},\n",
    "                {'p':'paragraph','url':'https://www.ncbi.nlm.nih.gov/pmc/','title':'3','kwd':'keywords'}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "\n",
      "Ação saia\n"
     ]
    }
   ],
   "source": [
    "import webbrowser\n",
    "# from ast import literal_eval\n",
    "# with open('stems.txt','r') as myf:\n",
    "#     s = myf.read()\n",
    "#     stems = literal_eval(s)\n",
    "for key in stems.keys():\n",
    "    i = 0\n",
    "    while i < len(stems[key]):\n",
    "        article = stems[key][i]\n",
    "        print article['title'],'\\n'\n",
    "#         print article['kwd'],'\\n'\n",
    "#         print article['p'],'\\n'\n",
    "        \n",
    "        apagar = re.compile(\"(apa|del|rem)\",re.IGNORECASE)\n",
    "        url = re.compile(\"(url|link|ender|site|abr)\",re.IGNORECASE)\n",
    "        proximo = re.compile(\"(con|ava|pro|nex)\",re.IGNORECASE)\n",
    "        sair = re.compile(\"(sai|lea|exi|fin)\",re.IGNORECASE)\n",
    "        \n",
    "        match = False\n",
    "        while not match:\n",
    "            act = raw_input(\"Ação \")\n",
    "            if apagar.match(act):\n",
    "                print 'apagando'\n",
    "                stems[key].remove(article)\n",
    "                match = True\n",
    "                i -= 1\n",
    "            elif url.match(act):\n",
    "                print 'abrindo'\n",
    "                i -= 1\n",
    "                webbrowser.open(article['url'])\n",
    "                match = True\n",
    "            elif proximo.match(act) or act == '':\n",
    "                print 'continuando'\n",
    "                match = True\n",
    "                continue\n",
    "            elif sair.match(act):\n",
    "                i = len(stems[key])\n",
    "                match = True\n",
    "            else:\n",
    "                print 'invalido!'\n",
    "        i += 1\n",
    "    with open('stem.txt', 'w') as myf:\n",
    "        myf.write(str(stems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'term': [{'kwd': 'keywords',\n",
       "   'p': 'paragraph',\n",
       "   'title': '1',\n",
       "   'url': 'https://www.ncbi.nlm.nih.gov/pmc/'},\n",
       "  {'kwd': 'keywords',\n",
       "   'p': 'paragraph',\n",
       "   'title': '2',\n",
       "   'url': 'https://www.ncbi.nlm.nih.gov/pmc/'},\n",
       "  {'kwd': 'keywords',\n",
       "   'p': 'paragraph',\n",
       "   'title': '3',\n",
       "   'url': 'https://www.ncbi.nlm.nih.gov/pmc/'}]}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('stem.txt','r') as myf:\n",
    "    from ast import literal_eval\n",
    "    s = myf.read()\n",
    "    stems = literal_eval(s)\n",
    "stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apagar = re.compile(\"(apa|del|rem)\",re.IGNORECASE)\n",
    "url = re.compile(\"(url|link|ender|site|abr)\",re.IGNORECASE)\n",
    "proximo = re.compile(\"(con|ava|pro|nex)\",re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-118-4f66ff2f2a6f>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-118-4f66ff2f2a6f>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    i++\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "i++\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = raw_input(\"\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "from ast import literal_eval\n",
    "import re\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "\n",
    "filename = \"thread_stems2017-11-30-16:30:19.409350.txt\"\n",
    "with open(filename,'r') as myf:\n",
    "    print '[*] Extraindo artigos de', filename\n",
    "    s = myf.read()\n",
    "    stems = literal_eval(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient Assessment AND image segmentation  =  8\n",
      ">>>>>>>>> Patient Assessment AND image segmentation\n",
      "Multi-Atlas Segmentation of Biomedical Images: A Survey \n",
      "\n",
      "Multi-atlas segmentation, Label fusion, Survey \n",
      "\n",
      "Multi-atlas segmentation (MAS), first introduced and popularized by the pioneering work of Rohlfing, Brandt, Menzel and Maurer Jr (2004), Klein, Mensh, Ghosh, Tourville and Hirsch (2005), and Heckemann, Hajnal, Aljabar, Rueckert and Hammers (2006), is becoming one of the most widely-used and successful image segmentation techniques in biomedical applications. By manipulating and utilizing the entire dataset of “atlases” (training images that have been previously labeled, e.g., manually by an expert), rather than some model-based average representation, MAS has the flexibility to better capture anatomical variation, thus offering superior segmentation accuracy. This benefit, however, typically comes at a high computational cost. Recent advancements in computer hardware and image processing software have been instrumental in addressing this challenge and facilitated the wide adoption of MAS. Today, MAS has come a long way and the approach includes a wide array of sophisticated algorithms that employ ideas from machine learning, probabilistic modeling, optimization, and computer vision, among other fields. This paper presents a survey of published MAS algorithms and studies that have applied these methods to various biomedical problems. In writing this survey, we have three distinct aims. Our primary goal is to document how MAS was originally conceived, later evolved, and now relates to alternative methods. Second, this paper is intended to be a detailed reference of past research activity in MAS, which now spans over a decade (2003 – 2014) and entails novel methodological developments and application-specific solutions. Finally, our goal is to also present a perspective on the future of MAS, which, we believe, will be one of the dominant approaches in biomedical image segmentation.Publisher's Disclaimer: This is a PDF file of an unedited manuscript that has been accepted for publication. As a service to our customers we are providing this early version of the manuscript. The manuscript will undergo copyediting, typesetting, and review of the resulting proof before it is published in its final citable form. Please note that during the production process errors may be discovered which could affect the content, and all legal disclaimers that apply to the journal pertain. \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-90dfbf23227c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mact\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Ação \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mapagar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[1;32mprint\u001b[0m \u001b[1;34m'apagando'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/diego/.virtualenvs/estudos/local/lib/python2.7/site-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    675\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    678\u001b[0m         )\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/diego/.virtualenvs/estudos/local/lib/python2.7/site-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    705\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for key in stems.keys():\n",
    "    i = 0\n",
    "    while i < len(stems[key]):\n",
    "        clear_output(wait=True)\n",
    "        print key,' = ',len(stems[key])\n",
    "        print '>>>>>>>>>', key\n",
    "        article = stems[key][i]\n",
    "        print article['title'],'\\n'\n",
    "        print article['kwd'],'\\n'\n",
    "        print article['p'],'\\n'\n",
    "        \n",
    "        apagar = re.compile(\"(apa|del|rem)\",re.IGNORECASE)\n",
    "        url = re.compile(\"(url|link|ender|site|abr|ope)\",re.IGNORECASE)\n",
    "        proximo = re.compile(\"(con|ava|pro|nex)\",re.IGNORECASE)\n",
    "        sair = re.compile(\"(sai|lea|exi|fin)\",re.IGNORECASE)\n",
    "        \n",
    "        match = False\n",
    "        while not match:\n",
    "            sleep(0.5)\n",
    "            act = raw_input(\"Ação \")\n",
    "            if apagar.match(act):\n",
    "                print 'apagando'\n",
    "                stems[key].remove(article)\n",
    "                match = True\n",
    "                i -= 1\n",
    "            elif url.match(act):\n",
    "                print 'abrindo'\n",
    "                i -= 1\n",
    "                webbrowser.open(article['url'])\n",
    "                match = True\n",
    "                sleep(1.5)\n",
    "            elif proximo.match(act) or act == '':\n",
    "                print 'continuando'\n",
    "                match = True\n",
    "                continue\n",
    "            elif sair.match(act):\n",
    "                i = len(stems[key])\n",
    "                match = True\n",
    "            else:\n",
    "                print 'invalido!'\n",
    "        i += 1\n",
    "    filename = \"thread_stems\" + str(datetime.now()).replace(' ','-') + '.txt'\n",
    "    with open(filename, 'w') as myf:\n",
    "        myf.write(str(stems))\n",
    "        print '[*] resultados salvos em',filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    clear_output()\n",
    "    print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tomography AND Artificial Intelligence',\n",
       " 'Arterial Coronary Syndrome AND Deep Learning',\n",
       " 'Patient Assessment AND Deep Learning',\n",
       " 'Coronary Artery Disease AND Artificial Intelligence',\n",
       " 'Tomography AND image segmentation',\n",
       " 'Coronary Artery Disease AND Deep Learning',\n",
       " 'Patient Assessment AND Artificial Intelligence',\n",
       " 'Risk Stratification AND Deep Learning',\n",
       " 'Patient Assessment AND Image processing',\n",
       " 'Patient Assessment AND image segmentation',\n",
       " 'Angiography AND Deep Learning',\n",
       " 'Arterial Coronary Syndrome AND Image processing',\n",
       " 'Angiography AND image segmentation',\n",
       " 'Arterial Coronary Syndrome AND image segmentation',\n",
       " 'Angiography AND Artificial Intelligence',\n",
       " 'Angiography AND Image processing',\n",
       " 'Risk Stratification AND Image processing',\n",
       " 'Risk Score AND image segmentation',\n",
       " 'Risk Score AND Deep Learning',\n",
       " 'Coronary Artery Disease AND Image processing',\n",
       " 'Tomography AND Image processing',\n",
       " 'Coronary Artery Disease AND image segmentation',\n",
       " 'Risk Stratification AND Artificial Intelligence',\n",
       " 'Risk Score AND Artificial Intelligence',\n",
       " 'Arterial Coronary Syndrome AND Artificial Intelligence',\n",
       " 'Tomography AND Deep Learning',\n",
       " 'Risk Score AND Image processing',\n",
       " 'Risk Stratification AND image segmentation']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stems.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
